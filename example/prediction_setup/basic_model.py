"""Basic test for the ML model."""
from __future__ import print_function
from __future__ import absolute_import

import seaborn as sns
import pandas as pd
import matplotlib.pyplot as plt

from ase.ga.data import DataConnection
from atoml.data_setup import get_unique, get_train
from atoml.particle_fingerprint import ParticleFingerprintGenerator
from atoml.fingerprint_setup import return_fpv
from atoml.feature_preprocess import normalize
from atoml.predict import GaussianProcess
from atoml.utilities import clean_variance

# Decide whether to remove output and print graph.
cleanup = True
plot = False

# Connect database generated by a GA search.
db = DataConnection('../../data/gadb.db')

# Get all relaxed candidates from the db file.
print('Getting candidates from the database')
all_cand = db.get_all_relaxed_candidates(use_extinct=False)

# Setup the test and training datasets.
testset = get_unique(atoms=all_cand, size=500, key='raw_score')
trainset = get_train(atoms=all_cand, size=500, taken=testset['taken'],
                     key='raw_score')

# Get the list of fingerprint vectors and normalize them.
print('Getting the fingerprint vectors')
fpv = ParticleFingerprintGenerator(get_nl=False, max_bonds=13)
test_fp = return_fpv(testset['atoms'], [fpv.nearestneighbour_fpv,
                                        fpv.bond_count_fpv])
train_fp = return_fpv(trainset['atoms'], [fpv.nearestneighbour_fpv,
                                          fpv.bond_count_fpv])

c = clean_variance(train=train_fp, test=test_fp)
test_fp = c['test']
train_fp = c['train']


def do_predict(train, test, train_target, test_target, hopt=False):
    """Function to make predictions."""
    # Scale features.
    nfp = normalize(train_matrix=train, test_matrix=test)

    # Do the predictions.
    pred = gp.get_predictions(train_fp=nfp['train'],
                              test_fp=nfp['test'],
                              train_target=train_target,
                              test_target=test_target,
                              get_validation_error=True,
                              get_training_error=True,
                              optimize_hyperparameters=hopt)

    if plot:
        pred['actual'] = test_target
        index = [i for i in range(len(test_fp))]
        df = pd.DataFrame(data=pred, index=index)
        with sns.axes_style("white"):
            sns.regplot(x='actual', y='prediction', data=df)
        plt.title('Validation RMSE: {0:.3f}'.format(
            pred['validation_rmse']['average']))
        plt.show()

    return pred


# Set up the prediction routine.
kdict = {'k1': {'type': 'gaussian', 'width': 0.5}}
gp = GaussianProcess(kernel_dict=kdict, regularization=0.001)

print('Original parameters')
a = do_predict(train=train_fp, test=test_fp, train_target=trainset['target'],
               test_target=testset['target'], hopt=False)

# Print the error associated with the predictions.
print('Training error:', a['training_rmse']['average'])
print('Model error:', a['validation_rmse']['average'])

# Try with hyperparameter optimization.
kdict = {'k1': {'type': 'gaussian', 'width': 1.}}
gp = GaussianProcess(kernel_dict=kdict, regularization=0.001)

print('Optimized parameters')
a = do_predict(train=train_fp, test=test_fp, train_target=trainset['target'],
               test_target=testset['target'], hopt=True)

# Print the error associated with the predictions.
print('Training error:', a['training_rmse']['average'])
print('Model error:', a['validation_rmse']['average'])
